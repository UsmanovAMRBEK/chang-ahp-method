{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 100 Table to 1 table with geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LMU_3(path):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    persons_data = np.load(path)\n",
    "\n",
    "    dc1 = np.ones((3,3))\n",
    "    for i in range(100):\n",
    "        dc1*=persons_data[i][0]**(1/100)\n",
    "    \n",
    "    dc2 = np.ones((3,3))\n",
    "    for i in range(100):\n",
    "        dc2*=persons_data[i][1]**(1/100)\n",
    "\n",
    "    dc3 = np.ones((3,3))\n",
    "    for i in range(100):\n",
    "        dc3*=persons_data[i][1]**(1/100)\n",
    "\n",
    "    alldc = dc1+dc2+dc3\n",
    "    df1 = pd.DataFrame(dc1,index = ['A','B','C'])\n",
    "    df2 = pd.DataFrame(dc2, index = list(\"ABC\"))\n",
    "    df3 = pd.DataFrame(dc3, index = list(\"ABC\"))\n",
    "    ret_data = [df1,df2,df3]\n",
    "\n",
    "    pandas_alldc = pd.DataFrame(alldc)\n",
    "    pandas_alldc.index = ['A','B','C']\n",
    "    pandas_alldc.columns = ['L','M','U']\n",
    "\n",
    "    return pandas_alldc, ret_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LMU_4(path):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    persons_data = np.load(path)\n",
    "\n",
    "    dc1 = np.ones((4,3))\n",
    "    for i in range(100):\n",
    "        dc1*=persons_data[i][0]**(1/100)\n",
    "    \n",
    "    dc2 = np.ones((4,3))\n",
    "    for i in range(100):\n",
    "        dc2*=persons_data[i][1]**(1/100)\n",
    "\n",
    "    dc3 = np.ones((4,3))\n",
    "    for i in range(100):\n",
    "        dc3*=persons_data[i][1]**(1/100)\n",
    "\n",
    "    dc4 = np.ones((4,3))\n",
    "    for i in range(100):\n",
    "        dc4*=persons_data[i][1]**(1/100)\n",
    "\n",
    "    alldc = dc1+dc2+dc3+dc4\n",
    "    df1 = pd.DataFrame(dc1, index = list(\"ABCD\"))\n",
    "    df2 = pd.DataFrame(dc2, index = list(\"ABCD\"))\n",
    "    df3 = pd.DataFrame(dc3, index = list(\"ABCD\"))\n",
    "    df4 = pd.DataFrame(dc4, index = list(\"ABCD\"))\n",
    "    ret_data = [df1,df2,df3,df4]\n",
    "\n",
    "\n",
    "    pandas_alldc = pd.DataFrame(alldc)\n",
    "    pandas_alldc.index = ['A','B','C','D']\n",
    "    pandas_alldc.columns = ['L','M','U']\n",
    "\n",
    "    return pandas_alldc, ret_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activate(pandas_alldc):\n",
    "    pandas_alldc['L'] = pandas_alldc['L']*(1/pandas_alldc['L'].sum())\n",
    "    pandas_alldc['M'] = pandas_alldc['M']*(1/pandas_alldc['M'].sum())\n",
    "    pandas_alldc['U'] = pandas_alldc['U']*(1/pandas_alldc['U'].sum())\n",
    "    return pandas_alldc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function row_to_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row2vector(active_data):\n",
    "    import numpy as np\n",
    "    if active_data.size==9:\n",
    "        s1 = np.array(active_data.iloc[[0]])\n",
    "        s2 = np.array(active_data.iloc[[1]])\n",
    "        s3 = np.array(active_data.iloc[[2]])\n",
    "        return [s1,s2,s3]\n",
    "    else:\n",
    "        s1 = np.array(active_data.iloc[[0]])\n",
    "        s2 = np.array(active_data.iloc[[1]])\n",
    "        s3 = np.array(active_data.iloc[[2]])\n",
    "        s4 = np.array(active_data.iloc[[3]])\n",
    "        return [s1,s2,s3,s4]\n",
    "    return \"xatolik\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Membership (Si > Sj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vM2_M1(M2, M1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        M2(l2,m2,u2)\n",
    "        M1(l1,m1,u1)\n",
    "    return: V(M2>=M1)\n",
    "    \"\"\"\n",
    "    M1=M1[0]; M2=M2[0]\n",
    "    if M2[1]>=M1[1]:\n",
    "        return 1\n",
    "    # elif M1[0]>M2[2]:\n",
    "    #     return 0\n",
    "    else:\n",
    "        return (M1[0]-M2[2])/( (M2[1]-M2[2]) - (M1[1]-M1[0]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FINAL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_data(active_data):\n",
    "    if active_data.size==9:\n",
    "        s1, s2 ,s3 = row2vector(active_data)\n",
    "\n",
    "        s1_s2 = vM2_M1(s1,s2)\n",
    "        s1_s3 = vM2_M1(s1,s3)\n",
    "        min_s1 = min(s1_s2,s1_s3)\n",
    "\n",
    "        s2_s1 = vM2_M1(s2,s1)\n",
    "        s2_s3 = vM2_M1(s2,s3)\n",
    "        min_s2 = min(s2_s1, s2_s3)\n",
    "\n",
    "        s3_s1 = vM2_M1(s3,s1)\n",
    "        s3_s2 = vM2_M1(s3,s2)\n",
    "        min_s3 = min(s3_s1,s3_s2)\n",
    "\n",
    "        final_data_s1 = pd.DataFrame([s1_s2,s1_s3,min_s1], index=['s1>s2', 's1>s3','min_s1'])\n",
    "        final_data_s2 = pd.DataFrame([s2_s1,s2_s3,min_s2], index=['s2>s1', 's2>s3','min_s2'])\n",
    "        final_data_s3 = pd.DataFrame([s3_s1,s3_s2,min_s3], index=['s3>s1', 's3>s2','min_s3'])\n",
    "        return final_data_s1,final_data_s2,final_data_s3\n",
    "    else:\n",
    "        s1, s2 ,s3, s4 = row2vector(active_data)\n",
    "\n",
    "        s1_s2 = vM2_M1(s1,s2)\n",
    "        s1_s3 = vM2_M1(s1,s3)\n",
    "        s1_s4 = vM2_M1(s1,s4)\n",
    "        min_s1 = min(s1_s2,s1_s3,s1_s4)\n",
    "\n",
    "\n",
    "        s2_s1 = vM2_M1(s2,s1)\n",
    "        s2_s3 = vM2_M1(s2,s3)\n",
    "        s2_s4 = vM2_M1(s2,s4)\n",
    "        min_s2 = min(s2_s1,s2_s3,s2_s4)\n",
    "\n",
    "\n",
    "        s3_s1 = vM2_M1(s3,s1)\n",
    "        s3_s2 = vM2_M1(s3,s2)\n",
    "        s3_s4 = vM2_M1(s3,s4)\n",
    "        min_s3 = min(s3_s1,s3_s2,s3_s4)\n",
    "\n",
    "\n",
    "        s4_s1 = vM2_M1(s4,s1)\n",
    "        s4_s2 = vM2_M1(s4,s2)\n",
    "        s4_s3 = vM2_M1(s4,s3)\n",
    "        min_s4 = min(s4_s1,s4_s2,s4_s3)\n",
    "\n",
    "        final_data_s1 = pd.DataFrame([s1_s2,s1_s3,s1_s4,min_s1], index=['s1>s2', 's1>s3','s1>s4', 'min_s1'])\n",
    "        final_data_s2 = pd.DataFrame([s2_s1,s2_s3,s2_s4,min_s2], index=['s2>s1', 's2>s3','s2>s4','min_s2'])\n",
    "        final_data_s3 = pd.DataFrame([s3_s1,s3_s2,s3_s4,min_s3], index=['s3>s1', 's3>s2','s3>s4','min_s3'])\n",
    "        final_data_s4 = pd.DataFrame([s4_s1,s4_s2,s4_s3,min_s4], index=['s4>s1', 's4>s2','s4>s3','min_s4'])\n",
    "        return final_data_s1,final_data_s2,final_data_s3,final_data_s4\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_excel(path,index):\n",
    "    data, ret_data = LMU_3(path)\n",
    "    data_copy = data.copy()\n",
    "    active_data = activate(data)\n",
    "    f1, f2, f3 = final_data(active_data)\n",
    "\n",
    "    sum_min = f1.iloc[[2]].values+f2.iloc[[2]].values+f3.iloc[[2]].values\n",
    "    sum_min_pd = pd.DataFrame(sum_min,index=['sum_min'])\n",
    "\n",
    "    lst = [[int(f1.iloc[[2]].values/sum_min),int(f2.iloc[[2]].values/sum_min),int(f3.iloc[[2]].values/sum_min)]]\n",
    "    d_result = pd.DataFrame(lst,index=list('d'))\n",
    "\n",
    "    def multiple_dfs(df_list, sheets, file_name, spaces):\n",
    "        writer = pd.ExcelWriter(file_name,engine='xlsxwriter')   \n",
    "        row = 0\n",
    "        for dataframe in df_list:\n",
    "            dataframe.to_excel(writer,sheet_name=sheets,startrow=row , startcol=0)   \n",
    "            row = row + len(dataframe.index) + spaces + 1\n",
    "        writer.save()\n",
    "\n",
    "    # list of dataframes\n",
    "    dfs = [ret_data[0],ret_data[1],ret_data[2], data_copy,active_data,f1,f2,f3, sum_min_pd, d_result]\n",
    "\n",
    "    # run function\n",
    "    multiple_dfs(dfs, 'Validation', f'test{index}.xlsx', 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4xn matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_excel4(path,index):\n",
    "    data, ret_data = LMU_4(path)\n",
    "    active_data = activate(data)\n",
    "    f1, f2, f3, f4 = final_data(active_data)\n",
    "\n",
    "    sum_min = f1.iloc[[2]].values+f2.iloc[[2]].values+f3.iloc[[2]].values+f4.iloc[[2]].values\n",
    "    sum_min_pd = pd.DataFrame(sum_min,index=['sum_min'])\n",
    "\n",
    "    lst = [[int(f1.iloc[[2]].values/sum_min),int(f2.iloc[[2]].values/sum_min),int(f3.iloc[[2]].values/sum_min),int(f4.iloc[[2]].values/sum_min)]]\n",
    "    d_result = pd.DataFrame(lst,index=list('d'))\n",
    "\n",
    "    def multiple_dfs(df_list, sheets, file_name, spaces):\n",
    "        writer = pd.ExcelWriter(file_name,engine='xlsxwriter')   \n",
    "        row = 0\n",
    "        for dataframe in df_list:\n",
    "            dataframe.to_excel(writer,sheet_name=sheets,startrow=row , startcol=0)   \n",
    "            row = row + len(dataframe.index) + spaces + 1\n",
    "        writer.save()\n",
    "\n",
    "    # list of dataframes\n",
    "    dfs = [ret_data[0],ret_data[1],ret_data[2],ret_data[3], data,active_data,f1,f2,f3,f4, sum_min_pd, d_result]\n",
    "\n",
    "    # run function\n",
    "    multiple_dfs(dfs, 'Validation', f'test{index}.xlsx', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prep_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amrbe\\AppData\\Local\\Temp\\ipykernel_14796\\452369914.py:19: FutureWarning: save is not part of the public API, usage can give in unexpected results and will be removed in a future version\n",
      "  writer.save()\n"
     ]
    }
   ],
   "source": [
    "get_data_excel('./person_prep_data_2.npy', index=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prep_data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amrbe\\AppData\\Local\\Temp\\ipykernel_14796\\452369914.py:19: FutureWarning: save is not part of the public API, usage can give in unexpected results and will be removed in a future version\n",
      "  writer.save()\n"
     ]
    }
   ],
   "source": [
    "# path = './person_prep_data_3.npy'\n",
    "# data3 = LMU_3('./person_prep_data_3.npy')\n",
    "get_data_excel('./person_prep_data_3.npy',index=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prep_data4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amrbe\\AppData\\Local\\Temp\\ipykernel_14796\\452369914.py:19: FutureWarning: save is not part of the public API, usage can give in unexpected results and will be removed in a future version\n",
      "  writer.save()\n"
     ]
    }
   ],
   "source": [
    "# data4 = LMU_3('./person_prep_data_4.npy')\n",
    "get_data_excel('./person_prep_data_4.npy',index=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prep_data5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amrbe\\AppData\\Local\\Temp\\ipykernel_14796\\452369914.py:19: FutureWarning: save is not part of the public API, usage can give in unexpected results and will be removed in a future version\n",
      "  writer.save()\n"
     ]
    }
   ],
   "source": [
    "# data5 = LMU_3('./person_prep_data_5.npy')\n",
    "get_data_excel('./person_prep_data_5.npy',index=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepdata1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff9e52c2b4dbab856b465dca49c0075cb6eacd86ebe1006c68cc4081b19476dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
